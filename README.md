# Continual Learning for Multitask Image Classification

A comprehensive implementation and evaluation of continual learning (CL) methods for sequential multitask classification on Split MNIST. This project compares three approaches: **Sequential Fine-Tuning (Naive CL)**, **Elastic Weight Consolidation (EWC)**, and **Experience Replay**, demonstrating how replay-based methods effectively mitigate catastrophic forgetting.

## ðŸŽ¯ Project Overview

**Continual Learning Challenge**: How can neural networks learn multiple tasks sequentially without "forgetting" previously learned knowledge?

This project addresses catastrophic forgetting through:
- âœ… **Naive Baseline**: Sequential fine-tuning (lower bound)
- âœ… **Regularization Method**: EWC with Fisher Information Matrix
- âœ… **Replay Method**: Experience Replay buffer with empirical validation
- âœ… **Rigorous Evaluation**: Accuracy matrix, forgetting metrics, comparative analysis

**Key Results**:
| Method | Final Accuracy | Avg Forgetting |
|--------|---|---|
| Naive CL | 66.67% | 41.50% |
| EWC (Î»=2000) | 70.12% | 37.14% |
| **Experience Replay** | **97.80%** | **1.84%** |

---

## ðŸ“¦ Repository Structure

```
Continual-Learning-for-Multitask-Image-Classification/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ LICENSE                            # MIT License
â”œâ”€â”€ .gitignore                         # Git ignore rules
â”‚
â”œâ”€â”€ cnn.py                             # Small CNN architecture
â”œâ”€â”€ eval.py                            # Evaluation metrics
â”œâ”€â”€ ewc.py                             # Elastic Weight Consolidation
â”œâ”€â”€ replay.py                          # Experience Replay buffer
â”œâ”€â”€ split_mnist.py                     # Split MNIST dataset
â”‚
â”œâ”€â”€ train_naive.py                     # Naive sequential fine-tuning
â”œâ”€â”€ train_ewc.py                       # EWC training script
â”œâ”€â”€ train_replay.py                    # Experience Replay training
â”œâ”€â”€ plot_results.py                    # Generate comparison plots
â”‚
â”œâ”€â”€ results/                           # Experiment outputs
â”‚   â”œâ”€â”€ naive/
â”‚   â”‚   â”œâ”€â”€ acc_matrix.npy
â”‚   â”‚   â””â”€â”€ metrics.json
â”‚   â”œâ”€â”€ ewc/
â”‚   â”‚   â”œâ”€â”€ acc_matrix.npy
â”‚   â”‚   â””â”€â”€ metrics.json
â”‚   â””â”€â”€ replay/
â”‚       â”œâ”€â”€ acc_matrix.npy
â”‚       â””â”€â”€ metrics.json
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ REPORT.md                      # Full 2-4 page research report
â”‚
â””â”€â”€ data/                              # MNIST dataset (auto-downloaded)
    â””â”€â”€ MNIST/
```

---

## ðŸš€ Quick Start

### Prerequisites
- **Python 3.8+**
- **CUDA 12.4+** (optional, for GPU acceleration)
- **GPU**: RTX 4060 or equivalent (recommended, CPU also works)

### Installation

1. **Clone the repository**:
```bash
git clone https://github.com/NANInithin/Continual-Learning-for-Multitask-Image-Classification.git
cd Continual-Learning-for-Multitask-Image-Classification
```

2. **Create a virtual environment**:
```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. **Install dependencies**:
```bash
pip install -U pip
pip install -r requirements.txt

# For GPU (CUDA 12.4):
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

4. **Verify GPU access (optional)**:
```bash
python -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\"}')"
```

---

## ðŸ“Š Running Experiments

### 1. Naive Sequential Fine-Tuning (Baseline)
```bash
python train_naive.py
```
**Output**: Results saved to `results/naive/`

### 2. Elastic Weight Consolidation (EWC)
```bash
python train_ewc.py
```
**Hyperparameter**: Adjust `EWC_LAMBDA` in `train_ewc.py` (default: 2000)

### 3. Experience Replay
```bash
python train_replay.py
```
**Configuration**: Modify `SAMPLES_PER_TASK` in `train_replay.py` (default: 200)

### 4. Generate Comparison Plots
```bash
python plot_results.py
```
**Outputs**:
- `comparison_accuracy.png` â€“ Accuracy curves across tasks
- `comparison_forgetting.png` â€“ Average forgetting bar chart

---

## ðŸ“ˆ Results Visualization

The project generates two key comparison plots:

### Figure 1: Average Accuracy vs Tasks
Shows how each method maintains accuracy as new tasks are learned. Experience Replay maintains ~99% accuracy across all tasks, while naive fine-tuning drops significantly.

### Figure 2: Average Forgetting Comparison
Bar chart comparing forgetting across methods. Replay achieves 20Ã— lower forgetting than naive CL (1.84% vs 41.50%).

---

## ðŸ”¬ Methodology

### Dataset: Split MNIST
- **5 sequential binary tasks** (digits {0,1}, {2,3}, {4,5}, {6,7}, {8,9})
- ~12,600 training samples per task
- Labels remapped to binary (0 or 1) within each task

### Model: Small CNN
```
Input (1Ã—28Ã—28)
  â†’ Conv2d(1, 32, 3Ã—3) + MaxPool2d(2Ã—2)
  â†’ Conv2d(32, 64, 3Ã—3) + MaxPool2d(2Ã—2)
  â†’ Dropout(0.25)
  â†’ Linear(64Ã—7Ã—7, 128) + ReLU
  â†’ Linear(128, 2)
Output (binary classification)
```
**Total Parameters**: ~230K

### Training Protocol
- **Optimizer**: SGD (momentum=0.9)
- **Learning Rate**: 0.01
- **Epochs per Task**: 5
- **Batch Size**: 64
- **Evaluation**: After each task, evaluate on all previously seen + current tasks

### Continual Learning Methods

#### 1. Sequential Fine-Tuning (Naive CL)
No explicit mechanism to prevent forgetting. Serves as lower bound baseline.

#### 2. Elastic Weight Consolidation (EWC)
Regularizes parameter updates based on Fisher Information Matrix:
```
L_EWC = L_task(Î¸) + (Î»/2) Ã— Î£_i [ (Î£_k F_i^(k)) Ã— (Î¸_i - Î¸_i*)^2 ]
```
- **Î» = 2000**: Stability-plasticity trade-off parameter
- **Fisher**: Diagonal approximation computed empirically on training data
- **Memory**: No data storage required

#### 3. Experience Replay
Maintains buffer of past task samples, replayed during new task training:
```
L_Replay = E_{(x,y) ~ D_t âˆª M} [ CrossEntropy(f_Î¸(x), y) ]
```
- **Buffer Size**: 200 samples per task (1,000 total)
- **Update**: Random sampling from each past task after completion

### Evaluation Metrics

**Accuracy Matrix** `A_{i,j}`: Accuracy on task j after training on task i

**Average Accuracy** (final): `AvgAcc = (1/T) Ã— Î£_j A_{T,j}`

**Forgetting per Task**: `F_j = max_{i<T} A_{i,j} - A_{T,j}`

**Overall Forgetting**: `F = (1/(T-1)) Ã— Î£_j F_j`

---

## ðŸ“š Key Findings

1. **Experience Replay Dominates**: 97.80% accuracy with 1.84% forgetting
2. **EWC Limited by Shared Head**: Label remapping creates output conflicts EWC cannot resolve
3. **Catastrophic Forgetting Severe**: Naive approach drops to 5.91% on Task 1 by end
4. **Replay Overhead Negligible**: 1,000 samples (~13 MB) for ~97% accuracy improvement

---

## ðŸ“– Documentation

- **Full Report**: See `docs/REPORT.md` for comprehensive 2-4 page analysis
- **Code Comments**: All modules well-documented with docstrings
- **Evaluation**: See results/ directory for detailed metrics

---

## ðŸ§ª Code Quality

- âœ… Modular, well-documented architecture
- âœ… PyTorch best practices
- âœ… Reproducible experiments
- âœ… Clear separation of concerns
- âœ… Comprehensive error handling

---

## ðŸ”§ Configuration

Main hyperparameters in individual scripts:

```python
# Data
BATCH_SIZE = 64
NUM_WORKERS = 2

# Training
EPOCHS_PER_TASK = 5
LR = 0.01
MOMENTUM = 0.9

# EWC
EWC_LAMBDA = 2000

# Replay
SAMPLES_PER_TASK = 200

# Device
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
```

---

## ðŸ“ Citation

If you use this project in your research, please cite:

```bibtex
@project{continual_learning_2025,
  author = {NANInithin},
  title = {Continual Learning for Multitask Image Classification},
  year = {2025},
  publisher = {GitHub},
  howpublished = {\url{https://github.com/NANInithin/Continual-Learning-for-Multitask-Image-Classification}}
}
```

---

## ðŸ“š References

- **Assignment**: TP2 - Advances in Machine Vision, Paris Saclay University
- **EWC**: Kirkpatrick et al. (2017). *Overcoming catastrophic forgetting in neural networks*. PNAS, 114(13), 3521â€“3526.
- **MNIST**: LeCun et al. (1998). *Gradient-based learning applied to document recognition*. IEEE, 86(11), 2278â€“2324.

---

## ðŸ¤ Contributing

Contributions welcome! Areas for improvement:

- Task-specific output heads (multi-head architecture)
- Additional CL methods (Progressive Neural Networks, PackNet, etc.)
- Alternative benchmarks (Permuted MNIST, CIFAR-100)
- Hyperparameter optimization framework
- Extended analysis notebook

---

## ðŸ“„ License

MIT License â€“ See LICENSE file for details

---

## ðŸ‘¤ Author

**NANInithin**  
Paris Saclay University, Master's in Machine Vision and AI  
December 2025

---

## âš¡ Quick Troubleshooting

| Issue | Solution |
|-------|----------|
| CUDA out of memory | Reduce `BATCH_SIZE` to 32 or 16 |
| Slow training | Ensure GPU is being used: `torch.cuda.is_available()` |
| Results don't match report | Check random seed, hardware differences may cause ~1% variance |
| Missing MNIST data | Scripts auto-download on first run; ensure internet connection |

---

## ðŸ“ž Support

For issues, questions, or suggestions:
1. Check existing GitHub Issues
2. Review documentation in `docs/REPORT.md`
3. Check code comments and docstrings
4. Open a new Issue with detailed description

---

**Last Updated**: December 2025  
**Status**: âœ… Complete & Ready for Submission
